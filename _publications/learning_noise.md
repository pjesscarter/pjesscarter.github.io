---
title: "Learning from Noise: Sample Complexity Bounds for Applied Machine Learning in Social Science"
collection: publications
permalink: /publication/2023-learning-noise
excerpt: Statistical learning increasingly provides a bridge between theoretical concepts and empirical realities in quantitative political science research. However, many concepts of interest to scholars are both highly multidimensional and inherently fuzzy, making even manual classification highly error-prone. The consequences of these issues for machine learning applications are not well understood, generating persistent uncertainty over what constitutes good enough data for applied research in social science, where available training sets are often relatively small. In this paper, we introduce a novel framework, learning from noise, taking advantage of researcher-specified bounds on conceptual complexity and labelling error to guarantee the sample size necessary to achieve a minimum level of accuracy with a precise level of confidence. In addition, a novel simulation-based approach, implemented in a companion R package, scR, permits researchers to determine appropriate bounds under a variety of sampling regimes for commonly-used machine learning models. Our method thus provides a simple analogue to power calculations for experimental work that allows applied researchers to assess the feasibility of applying statistical learning models at the design stage.
date: 2023-08-30
paperurl: 'https://pjesscarter.github.io/files/learning_noise.pdf'
citation: 'Carter, Perry and Choi, Dahyun. (2023). &quot;Learning from Noise: Sample Complexity Bounds for Applied Machine Learning in Social Science.&quot; <i>Working Paper</i>.'
---


[Access Draft Here](https://pjesscarter.github.io/files/learning_noise.pdf)

[Additional Materials](https://github.com/pjesscarter/scR)
